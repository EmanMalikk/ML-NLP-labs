#tokenization with split
file= open("")
textInFile= file.read()
print(textInFile)
tokens = textInFile.split()
print(tokens)